{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelslist = [] # Array to hold successful models for ensemble/bag methods\n",
    "traindf = pd.read_csv('data/train.csv')\n",
    "testdf = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0   0   F   0.550     0.430   0.150        0.7715          0.3285   \n",
       "1   1   F   0.630     0.490   0.145        1.1300          0.4580   \n",
       "2   2   I   0.160     0.110   0.025        0.0210          0.0055   \n",
       "3   3   M   0.595     0.475   0.150        0.9145          0.3755   \n",
       "4   4   I   0.555     0.425   0.130        0.7820          0.3695   \n",
       "\n",
       "   Whole weight.2  Shell weight  Rings  \n",
       "0          0.1465        0.2400     11  \n",
       "1          0.2765        0.3200     11  \n",
       "2          0.0030        0.0050      6  \n",
       "3          0.2055        0.2500     10  \n",
       "4          0.1600        0.1975      9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head() # Viewing sample rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.drop(['id'], axis=1, inplace=True) # Eliminating redundant id column\n",
    "testdf = testdf.set_index('id')\n",
    "\n",
    "# One-hot encoding the sex column in train and test data\n",
    "traindf['Sex'] = traindf['Sex'].map({'F': 'Female', 'I': 'Idk', 'M': 'Male'}) # \n",
    "traindf = pd.get_dummies(traindf, columns=['Sex'], prefix='', prefix_sep='', dtype=np.float32)\n",
    "\n",
    "testdf['Sex'] = testdf['Sex'].map({'F': 'Female', 'I': 'Idk', 'M': 'Male'})\n",
    "testdf = pd.get_dummies(testdf, columns=['Sex'], prefix='', prefix_sep='', dtype=np.float32)\n",
    "\n",
    "# Defining the target for the model\n",
    "target = traindf['Rings']\n",
    "traindf.drop(['Rings'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(traindf, target, test_size=0.2, random_state=69) # Creating validation subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error (RMSLE) between the true and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): Array of true values.\n",
    "    y_pred (array-like): Array of predicted values.\n",
    "\n",
    "    Returns:\n",
    "    tf.Tensor: The RMSLE value as a TensorFlow tensor.\n",
    "    \"\"\"\n",
    "    return tf.sqrt(tf.reduce_mean((tf.math.log(1+y_pred.astype('float32'))-tf.math.log(1+y_true.astype('float32')))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(model, testdf):\n",
    "    \"\"\"\n",
    "    Generates a submission file for a Kaggle competition.\n",
    "    This function takes a trained model and a test DataFrame, makes predictions,\n",
    "    and outputs a CSV file named 'submission.csv' with the predictions.\n",
    "    Args:\n",
    "        model: The trained model used for making predictions.\n",
    "        testdf (pd.DataFrame): The test DataFrame containing the features for prediction.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(testdf)\n",
    "    rounded_predictions = predictions\n",
    "    outputdf = pd.DataFrame(rounded_predictions, columns=['Rings'])\n",
    "    outputdf['id'] = testdf.index\n",
    "\n",
    "    cols = list(outputdf.columns)\n",
    "    cols.reverse()\n",
    "    outputdf = outputdf[cols]\n",
    "    outputdf.to_csv('submission.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb_model(xgb_model, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evaluates one XGBoost model using Root Mean Squared Logarithmic Error (RMSLE).\n",
    "    Parameters:\n",
    "    xgb_model (xgboost.Booster): Trained XGBoost model to be evaluated.\n",
    "    X_val (pd.DataFrame or np.ndarray): Validation features.\n",
    "    y_val (pd.Series or np.ndarray): True values for the validation set.\n",
    "    Returns:\n",
    "    None\n",
    "    Prints:\n",
    "    - Sum of NaN values in the logarithm of the true values (y_test_log).\n",
    "    - Sum of NaN values in the logarithm of the predicted values (y_pred_log).\n",
    "    - Root Mean Squared Logarithmic Error (RMSLE) of the predictions.\n",
    "    \"\"\"\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    y_test_log = np.log1p(y_val) \n",
    "    y_pred_log = np.log1p(y_pred)\n",
    "\n",
    "    print(\"Sum of NaN values in y_test_log:\", np.isnan(y_test_log).sum())\n",
    "    print(\"Sum of NaN values in y_pred_log:\", np.isnan(y_pred_log).sum())\n",
    "\n",
    "    rmsle = root_mean_squared_error(y_test_log, y_pred_log) \n",
    "    print(\"RMSLE:\", rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, booster=gbtree, eta=0.2, max_depth=6, n_estimators=340, subsample=0.95; total time=   2.1s\n",
      "[CV] END alpha=0.1, booster=gbtree, eta=0.2, max_depth=6, n_estimators=340, subsample=0.95; total time=   2.1s\n",
      "[CV] END alpha=0.1, booster=gbtree, eta=0.2, max_depth=6, n_estimators=340, subsample=0.95; total time=   2.1s\n",
      "[CV] END alpha=0.1, booster=gbtree, eta=0.2, max_depth=6, n_estimators=340, subsample=0.95; total time=   2.1s\n",
      "[CV] END alpha=0.1, booster=gbtree, eta=0.2, max_depth=6, n_estimators=340, subsample=0.95; total time=   2.1s\n",
      "Best Params: {'alpha': 0.1, 'booster': 'gbtree', 'eta': 0.2, 'max_depth': 6, 'n_estimators': 340, 'subsample': 0.95}\n",
      "Best Score: -0.14905989556212912\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [340],\n",
    "    'max_depth': [6],\n",
    "    'subsample': [0.95],\n",
    "    'eta': [0.2],\n",
    "    'alpha': [0.1],\n",
    "    'booster': ['gbtree']\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor with the specified objective\n",
    "xgbr = xgb.XGBRegressor(objective='reg:squaredlogerror')\n",
    "\n",
    "# Initialize GridSearchCV with the XGBoost regressor, parameter grid, and other settings\n",
    "grid_search = GridSearchCV(xgbr, param_grid, scoring='neg_root_mean_squared_log_error', cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(traindf, target)\n",
    "\n",
    "# Print the best parameters and score from the grid search\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of NaN values in y_test_log: 0\n",
      "Sum of NaN values in y_pred_log: 0\n",
      "RMSLE: 0.15699401727509213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niranj/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the XGBoost model to the training data\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the XGBoost model on the validation set\n",
    "evaluate_xgb_model(xgbr, X_val, y_val)\n",
    "\n",
    "# Evaluate the best model from GridSearchCV on the validation set\n",
    "evaluate_xgb_model(best_model, X_val, y_val)\n",
    "\n",
    "# Append the best model to the models list for ensemble methods\n",
    "modelslist.append(best_model)\n",
    "\n",
    "# Generate submission file using the best model\n",
    "get_submission(best_model, testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'num_leaves': 31}\n",
    "RMSLE: 0.152062916732084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 600, 700],\n",
    "    'learning_rate': [0.08],\n",
    "    'num_leaves': [43],\n",
    "    'max_depth': [5],\n",
    "    'min_data_in_leaf': [19],\n",
    "    'lambda_l1': [0.1, 0.2],\n",
    "    'lambda_l2': [0.1, 0.2],\n",
    "    'min_gain_to_split': [0.1, 0.2],\n",
    "    'bagging_fraction': [0.9, 0.85],\n",
    "    'bagging_freq': [3, 5],\n",
    "    'feature_fraction': [1],\n",
    "    \"colsample_bytree\": [0.7],\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM regressor with the specified objective\n",
    "model = lgb.LGBMRegressor(n_jobs=-1, objective='regression')\n",
    "\n",
    "# Initialize GridSearchCV with the LightGBM regressor, parameter grid, and other settings\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_root_mean_squared_log_error')\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score from the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission(best_model, testdf) # Getting submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'learning_rate': [0.1],\n",
    "    'num_leaves': [31],\n",
    "    'max_depth': [5],\n",
    "    'min_data_in_leaf': [19],\n",
    "    'lambda_l1': [0.1],\n",
    "    'lambda_l2': [0.1],\n",
    "    'min_gain_to_split': [0.1],\n",
    "    'bagging_fraction': [0.9],\n",
    "    'bagging_freq': [3],\n",
    "    'feature_fraction': [0.9],\n",
    "    'max_bin': [255],\n",
    "    \"colsample_bytree\": [0.7],\n",
    "}\n",
    "0.15186426150275126\n",
    "\n",
    "Best Parameters: {'bagging_fraction': 0.9, 'bagging_freq': 3, 'colsample_bytree': 0.7, 'feature_fraction': 0.9, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'learning_rate': 0.1, 'max_bin': 255, 'max_depth': 5, 'min_data_in_leaf': 19, 'min_gain_to_split': 0.1, 'n_estimators': 500, 'num_leaves': 31}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalising Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_score(modelslist, y_val, X_val):\n",
    "    \"\"\"\n",
    "    Aggregates predictions from multiple models using a voting mechanism and calculates the Root Mean Squared Logarithmic Error (RMSLE).\n",
    "    Parameters:\n",
    "    modelslist (list): A list of trained models that support the predict method.\n",
    "    y_val (array-like): The true values for the validation set.\n",
    "    X_val (array-like): The input features for the validation set.\n",
    "    Returns:\n",
    "    None: Prints the RMSLE and the sum of NaN values in the log-transformed true and predicted values.\n",
    "    \"\"\"\n",
    "    predictionslist = []\n",
    "    for model in modelslist:\n",
    "        predictions = model.predict(X_val)\n",
    "        rounded_predictions = np.round(predictions).astype(int)\n",
    "        rounded_predictions = rounded_predictions.flatten()\n",
    "        predictionslist.append(rounded_predictions)\n",
    "    \n",
    "    finaloutput = []\n",
    "    for index, prediction in enumerate(predictionslist[0]):\n",
    "        if predictionslist[1][index] == predictionslist[2][index] == predictionslist[0][index]:\n",
    "            finaloutput.append(prediction)\n",
    "        elif predictionslist[0][index] == predictionslist[1][index]:\n",
    "            finaloutput.append(predictionslist[0][index])\n",
    "        elif predictionslist[0][index] == predictionslist[2][index]:\n",
    "            finaloutput.append(predictionslist[0][index])\n",
    "        elif predictionslist[1][index] == predictionslist[2][index]:\n",
    "            finaloutput.append(predictionslist[1][index])\n",
    "        else:\n",
    "            roundedoutput = np.round(np.mean([predictionslist[0][index], predictionslist[1][index], predictionslist[2][index]])).astype(int)\n",
    "            finaloutput.append(roundedoutput)\n",
    "    \n",
    "    y_test_log = np.log1p(y_val)\n",
    "    y_pred_log = np.log1p(finaloutput)\n",
    "\n",
    "    print(\"Sum of NaN values in y_test_log:\", np.isnan(y_test_log).sum())\n",
    "    print(\"Sum of NaN values in y_pred_log:\", np.isnan(y_pred_log).sum())\n",
    "\n",
    "    rmsle = root_mean_squared_error(y_test_log, y_pred_log) \n",
    "    print(\"RMSLE:\", rmsle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
